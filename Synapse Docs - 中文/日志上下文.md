### 日志上下文

为了帮助跟踪单个请求的处理，Synapse使用“`log context`”来跟踪它在任何给定时刻正在处理的请求。这是通过线程局部变量完成的；然后使用`logging.Filter`从线程局部变量中提取信息并将其添加到每个日志记录中。

日志上下文还用于CPU和数据库记账，以便我们可以跟踪哪些请求导致了高CPU使用或数据库活动。

`synapse.logging.context`模块提供了管理当前日志上下文的工具（以及提供`LoggingContextFilter`类）。

异步函数使整个事情变得复杂，因此本文档描述了它的工作原理以及如何编写遵循规则的代码。

在本文档中，“awaitable”指的是任何可以被`await`的对象。在Synapse的上下文中，这通常意味着协程或Twisted [`Deferred`](https://twistedmatrix.com/documents/current/api/twisted.internet.defer.Deferred.html)。

#### 没有异步代码的日志上下文

在没有任何异步魔法的情况下，事情就简单多了。与任何此类代码一样，规则是我们的函数应该保持原样：

```python
from synapse.logging import context         # 从未来的代码片段中省略

def handle_request(request_id):
    request_context = context.LoggingContext()

    calling_context = context.set_current_context(request_context)
    try:
        request_context.request = request_id
        do_request_handling()
        logger.debug("finished")
    finally:
        context.set_current_context(calling_context)

def do_request_handling():
    logger.debug("phew")  # 这将记录在request_id下
```

LoggingContext实现了上下文管理方法，因此上述代码可以更简洁地写为：

```python
def handle_request(request_id):
    with context.LoggingContext() as request_context:
        request_context.request = request_id
        do_request_handling()
        logger.debug("finished")

def do_request_handling():
    logger.debug("phew")
```

#### 使用日志上下文与可等待对象

Awaitables 打破了代码的线性流程，因此不再有一个单一的入口点来设置日志上下文和一个单一的出口点来移除它。

考虑上面的例子，其中 `do_request_handling` 需要执行一些阻塞操作，并返回一个可等待对象：

```python
async def handle_request(request_id):
    with context.LoggingContext() as request_context:
        request_context.request = request_id
        await do_request_handling()
        logger.debug("finished")
```

在上述流程中：

*   日志上下文已设置
*   `do_request_handling` 被调用，并返回一个可等待对象
*   `handle_request` 等待可等待对象
*   `handle_request` 的执行已暂停

因此我们已停止处理请求（可能会继续处理下一个请求），但未清除日志上下文。

为了规避这个问题，synapse 代码假设，无论何处有可等待对象，你都会想要 `await` 它。为此，在函数返回可等待对象的地方，我们采用以下约定：

**返回可等待对象的函数规则：**

> *   如果可等待对象已经完成，函数将以其开始时的相同日志上下文返回。
> *   如果可等待对象未完成，函数会在返回前清除日志上下文；当可等待对象完成时，它会在运行任何回调之前恢复日志上下文。

这听起来很复杂，但实际上这意味着很多代码（包括上面的例子）“就能工作”。有两种情况：

*   如果 `do_request_handling` 返回一个已完成的可等待对象，那么日志上下文仍然会保留。在这种情况下，执行将在 `await` 之后立即继续；“finished”行将记录在正确的上下文中，并且 `with` 块会在我们返回给调用者之前恢复原始上下文。
*   如果返回的可等待对象未完成， `do_request_handling` 会在返回前清除日志上下文。因此，当 `handle_request` `await` 可等待对象时，日志上下文是清除的。

一旦 `do_request_handling` 的可等待对象完成，它会在运行 `handle_request` 的第二部分之前恢复日志上下文，因此，“finished”行将再次记录在正确的上下文中，并且 `with` 块会恢复原始上下文。

顺便提一下，值得注意的是 `handle_request` 遵循我们的规则

*   尽管这只有在调用者有自己的 logcontext 并且在意它时才重要。

以下部分描述了在实现这些规则时可能遇到的陷阱和有用的模式。

始终等待你的可等待对象
-----------

每当你从函数中得到一个可等待对象时，你应该尽快对其进行 `await` 。不要通过；不要进行任何日志记录；不要调用任何其他函数。

```
async def fun():
    logger.debug("starting")
    await do_some_stuff()       # just like this

    coro = more_stuff()
    result = await coro         # also fine, of course

    return result
```

只要这个模式一直遵循到调用链的顶端，即设置日志上下文的地方，这将使事情顺利进行：只要 `do_some_stuff` 和 `more_stuff` 遵循上述规则，那么 `fun` 也会遵循。

忘记 `await` 太容易了：例如，如果我们忘记了 `do_some_stuff` 返回一个可等待对象，我们可能会不顾一切地继续。这会导致一团糟；最终可能会自行解决，但在此之前，大量内容将被记录在错误的上下文中。（通常，如果你忘记了 `await` ，其他事情会更明显地出错，所以在实践中这通常不是一个大问题。）

当然，有时候你需要对你的可等待对象做一些更复杂的处理——并非所有代码都遵循线性的 A 然后 B 然后 C 的模式。关于实现更复杂模式的说明在后续章节中。

#### 在你创建一个新的可等待对象时，请确保它遵循规则

大多数时候，可等待对象来自另一个突触函数。然而，有时我们需要创建一个新的可等待对象，或者从外部代码中得到一个可等待对象。我们需要确保它遵循我们的规则。

实现它的简单方法是使用 `context.make_deferred_yieldable` 。假设我们想实现 `sleep` ，它会返回一个延迟对象，该对象将在给定秒数后运行其回调。这可能会看起来像：

```
  # 不符合logcontext-rules的函数
def get_sleep_deferred(seconds):
    d = defer.Deferred()
    reactor.callLater(seconds, d.callback, None)
    return d
```

这不符合规则，但我们可以通过调用 `context.make_deferred_yieldable` 来修复它：

```
async def sleep(seconds):
    return await context.make_deferred_yieldable(get_sleep_deferred(seconds))
```

#### 发射并忘记

有时你想启动一连串的执行，但不等待其结果。这可能看起来像这样：

```
async def do_request_handling():
    await foreground_operation()

    # *don't* do this===
    background_operation()

    logger.debug("Request handling complete")

async def background_operation():
    await first_background_step()
    logger.debug("Completed first step")
    await second_background_step()
    logger.debug("Completed second step")
```

上面的代码在 `do_request_handling` 完成后在后台执行几个步骤。日志行仍然记录在 `request_context` 的日志上下文中，这可能是也可能不是你想要的。然而，上述代码有两个大问题。第一个问题是，如果 `background_operation` 返回一个不完整的可等待对象，它会期望其调用者立即 `await` ，因此会清除日志上下文。在这个例子中，这意味着'请求处理完成'将在没有上下文的情况下被记录。

第二个问题，可能更糟糕的是，当 `background_operation` 返回的可等待对象完成时，它会恢复原始的日志上下文。没有东西在等待这个可等待对象，所以日志上下文会泄漏到反应器中，并可能附着到某个未来的任意操作上。

对此有两个可能的解决方案。

一个选项是将对 `background_operation` 的调用用 `PreserveLoggingContext` 调用包围。这样在开始 `background_operation` 之前会重置日志上下文（因此当延迟完成时恢复的上下文将是空的日志上下文），并在继续前台进程之前恢复当前的日志上下文：

```
async def do_request_handling():
    await foreground_operation()

    # start background_operation off in the empty logcontext, to===
    # avoid leaking the current context into the reactor.===
    with PreserveLoggingContext():
        background_operation()

    # this will now be logged against the request context===
    logger.debug("Request handling complete")
```

显然，这个选项意味着在 `background_operation` 中执行的操作不会被记录在日志上下文中（尽管可以通过在 `background_operation` 中通过 `with LoggingContext(...)` 设置不同的日志上下文来修复这一点）。

第二种选择是使用 `context.run_in_background` ，它包装一个函数，使其即使返回不完整的可等待对象时也不会重置日志上下文，并在返回的可等待对象上添加一个回调以重置日志上下文。  
换句话说，它将一个遵循 Synapse 关于日志上下文和可等待对象规则的函数转变为一个更像外部函数的行为，与上一节描述的操作相反。它可以这样使用：

```
async def do_request_handling():
    await foreground_operation()

    context.run_in_background(background_operation)

===    # this will now be logged against the request context===
    logger.debug("Request handling complete")
```

#### 将 Synapse 延迟对象传递给第三方函数

这是一个典型的例子，我们希望通过 `defer.gatherResults` 收集两个或多个可等待对象：

```
a1 = operation1()
a2 = operation2()
a3 = defer.gatherResults([a1, a2])
```

这实际上是上面提到的火与忘问题的一个变体，我们启动了 `a1` 和 `a2` 而不等待它们。不同之处在于现在我们有第三方代码附加到它们的回调上。无论如何，火与忘部分给出的任一技术都将有效。

当然，由 `gather` 返回的新可等待对象需要被包装，以便在我们可以 yield 它之前遵循 logcontext 规则，如在你创建一个新的可等待对象时，使其遵循规则中所述。

因此，选项一：在开始收集操作之前重置日志上下文：

```
async def do_request_handling():
    with PreserveLoggingContext():
        a1 = operation1()
        a2 = operation2()
        result = await defer.gatherResults([a1, a2])
```

然而，在这种情况下，选项二，使用 `context.run_in_background` 几乎肯定更有意义，这样 `operation1` 和 `operation2` 都将记录在原始日志上下文中。这看起来像：

```
async def do_request_handling():
    a1 = context.run_in_background(operation1)
    a2 = context.run_in_background(operation2)

    result = await make_deferred_yieldable(defer.gatherResults([a1, a2]))
```

#### 关于可等待链的垃圾回收的说明

事实证明，我们的日志上下文规则与可等待链不兼容，这些链会被孤立并被垃圾回收。

想象一下，我们有一些代码看起来像这样：

```
listener_queue = []

def on_something_interesting():
    for d in listener_queue:
        d.callback("foo")

async def await_something_interesting():
    new_awaitable = defer.Deferred()
    listener_queue.append(new_awaitable)

    with PreserveLoggingContext():
        await new_awaitable
```

显然，这里的想法是我们有一堆事情在等待一个事件。（这只是这里问题的示例，但相对常见。）

现在让我们想象两个进一步的事情发生。首先，所有等待有趣事情发生的东西都消失了。（也许请求超时了，或者发生了更有趣的事情。）

其次，让我们假设我们决定有趣的事情永远不会发生，我们重置了监听队列：

```
def reset_listener_queue():
    listener_queue.clear()
```

因此，可等待链的两端现在都已经丢弃了它们的引用，可等待链现在被孤立了，将在某个时候被垃圾回收。注意 `await_something_interesting` 是一个协程，Python 将其实现为生成器函数。当 Python 垃圾回收生成器函数时，它会给它们一个清理的机会，通过让 `await` （或 `yield` ）引发一个 `GeneratorExit` 异常。在我们的例子中，这意味着 `__exit__` 处理程序将小心地恢复请求上下文，但现在没有东西在等待它的返回，所以请求上下文永远不会被清除。

重申一下，这个问题只会在一个可等待链的两端都被丢弃时出现。丢弃你应该在等待的可等待对象的引用是不好的做法，所以这种情况实际上并不常见。  
不幸的是，当这种情况发生时，它会导致泄露的日志上下文，这些上下文极难追踪。