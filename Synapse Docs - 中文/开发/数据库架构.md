### Synapse 数据库架构文件

Synapse 的数据库架构存储在 `synapse.storage.schema` 模块中。  

#### 逻辑数据库

Synapse 支持将其数据存储分散到多个物理数据库中（这对于大型安装非常有用），因此，架构文件根据它们适用的逻辑数据库进行拆分。  
在撰写本文时，支持以下“逻辑”数据库： * `state`
- 用于存储 Matrix 房间状态（更具体地说，`state_groups`、它们的关系和内容）。 * `main`
- 存储其他所有内容。  
此外，`common` 目录包含必须存在于*所有*物理数据库上的表的模式文件。

#### Synapse 模式版本

Synapse 通过“模式版本”来管理其数据库模式。  
这些主要用于在 Synapse 代码库回滚后数据库已更新的情况下，帮助避免混淆。  
它们的工作原理如下： 
* Synapse 代码库定义了一个常量 `synapse.storage.schema.SCHEMA_VERSION`，它表示该版本对数据库的期望。例如，截至 Synapse v1.36，该值为 `59`。  
* 数据库在 `schema_compat_version.compat_version` 中存储了一个“兼容版本”，它定义了与数据库兼容的最旧版本的 Synapse 的 `SCHEMA_VERSION`。  
在启动时，如果发现 `compat_version` 比 `SCHEMA_VERSION` 新，Synapse 将拒绝启动。  
Synapse 会自动从 `synapse.storage.schema.SCHEMA_COMPAT_VERSION` 更新此字段。
* 每当对数据库格式进行不兼容的更改时（通常通过 `delta` 文件），`synapse.storage.schema.SCHEMA_COMPAT_VERSION` 也会更新，以防止管理员意外回滚到过旧的 Synapse 版本。  

通常，目标是保持与至少一个或两个之前版本的 Synapse 兼容，因此任何重大更改往往需要多个版本发布和一些前瞻性规划来正确实现。  

作为一个工作示例：我们想删除 `room_stats_historical` 表。以下是可能的步骤。
1. 用替代实现替换任何从 `room_stats_historical` 读取的代码，但保留写入操作以防回滚到早期版本。  此外，增加 `synapse.storage.schema.SCHEMA_VERSION`。在本例中，没有现有代码从 `room_stats_historical` 读取数据，因此我们的起点是：
	v1.36.0：`SCHEMA_VERSION=59`，`SCHEMA_COMPAT_VERSION=59`   

2. 下一步（例如在 Synapse v1.37.0 中）：移除写入 `room_stats_historical` 的代码，但暂时不要删除该表，以防回滚到 v1.36.0。我们再次增加 `synapse.storage.schema.SCHEMA_VERSION`，但由于我们没有破坏与 v1.36 的兼容性，我们暂时不更新 `SCHEMA_COMPAT_VERSION`。  我们现在有：
	v1.37.0：`SCHEMA_VERSION=60`，`SCHEMA_COMPAT_VERSION=59`。
3. 稍后（例如在 Synapse v1.38.0 中）：我们可以完全移除该表。这将破坏与 v1.36.0 的兼容性，因此我们必须相应地更新`SCHEMA_COMPAT_VERSION`。  
这里没有必要更新 `synapse.storage.schema.SCHEMA_VERSION`，因为这里没有对 Synapse 代码库进行更改。因此我们得到：
	v1.38.0: `SCHEMA_VERSION=60`, `SCHEMA_COMPAT_VERSION=60`。  

如果对是否更新 `SCHEMA_VERSION` 存在疑问，通常最好倾向于进行更新。

#### 完整模式转储

在 `full_schemas` 目录中，只使用编号最新的快照（写作时为 `54`）。  
旧快照（例如，`16`）仅供历史参考。

##### 构建完整模式转储

如果您想重新创建这些模式，它们需要从一个已经运行了所有后台更新的数据库中生成。  
为此，请使用 `scripts-dev/make_full_schema.sh`。这将生成新的 `full.sql.postgres` 和 `full.sql.sqlite` 文件。  
确保已安装 postgres，然后运行：

```sh

 ./scripts-dev/make_full_schema.sh -p postgres_username -o output_dir/ 
```

注意：在撰写本文时，此脚本早于将数据库拆分为独立的`state`/`main`数据库之前，因此需要更新以正确处理此问题。  

#### Delta 文件

Delta 文件定义了从早期版本升级数据库所需的步骤。它们可以写成包含一系列 SQL 语句的文件，或者一个 Python 模块。  

Synapse 会记住它已经应用到数据库的哪些增量文件（它们存储在 `applied_schema_deltas` 表中），并且不会重新应用它们（即使某个文件随后被更新）。

增量文件应放置在名为 `synapse/storage/schema/<database>/delta/<version>/` 的目录中。它们会按字母数字顺序应用，因此按照惯例，文件名的前两个字符应为整数，例如 `01`，以便将文件按正确顺序排列。 

##### SQL 增量文件

这些文件应命名为`*.sql`，或者——对于仅适用于特定数据库引擎的更改——`*.sql.postgres`或`*.sql.sqlite`。例如，一个向`foo`表添加新列的增量文件可能被命名为`01add_bar_to_foo.sql`。请注意，我们的 SQL 解析器比较简单——它能理解注释（`--`和`/*...*/`），但对于需要在语句中间使用`;`的复杂语句（如`CREATE TRIGGER`），它无法处理，你需要使用 Python 增量文件。  

##### Python delta 文件

为了更大的灵活性，delta 文件可以采用 Python 模块的形式。  
这些文件应命名为 `*.py`。请注意，这里不支持特定于数据库引擎的模块
- 相反，您可以编写 `if isinstance(database_engine, PostgresEngine)` 或类似的代码。  
Python delta 模块应定义以下一个或两个函数： 

```python
import synapse.config.homeserver
import synapse.storage.engines
import synapse.storage.types

def run_create(
    cur: synapse.storage.types.Cursor,
    database_engine: synapse.storage.engines.BaseDatabaseEngine,
) -> None:
    """Called whenever an existing or new database is to be upgraded"""
    ...

def run_upgrade(
    cur: synapse.storage.types.Cursor,
    database_engine: synapse.storage.engines.BaseDatabaseEngine,
    config: synapse.config.homeserver.HomeServerConfig,
) -> None:
    """Called whenever an existing database is to be upgraded."""
    ...
```

#### 后台更新

有时将数据库迁移作为后台进程的一部分执行是合适的（而不是阻塞 Synapse 直到迁移完成）。  
特别是，当添加新列或新表时，这对于迁移数据非常有用。  
挂起的后台更新存储在 `background_updates` 表中，并通过唯一的名称、当前状态（以 JSON 格式存储）以及一些依赖信息来标识：* 是否需要前一个更新完成。  
* 更新完成的粗略排序。  
需要在 `background_updates` 表中添加一个新的后台更新： 

```sql

 INSERT INTO background_updates (ordering, update_name, depends_on, progress_json) VALUES (7706, 'my_background_update', 'a_previous_background_update', '{}'); 
```

然后需要在相应的数据存储中添加一个关联的处理程序： 

```python
self.db_pool.updates.register_background_update_handler(
    "my_background_update",
    update_handler=self._my_background_update,
)
```

可以执行几种类型的更新，请参见 `BackgroundUpdater`： * `register_background_update_handler`：用于自定义 SQL 的通用处理程序 * `register_background_index_update`：在后台创建索引 * `register_background_validate_constraint`：在后台验证约束（仅限 PostgreSQL） * `register_background_validate_constraint_and_delete_rows`：类似于 `register_background_validate_constraint`，但删除不符合约束的行。  
对于 `register_background_update_handler`，通用处理程序必须跟踪进度并最终完成后台更新： 

```python
async def _my_background_update(self, progress: JsonDict, batch_size: int) -> int:
    def _do_something(txn: LoggingTransaction) -> int:
        ...
        self.db_pool.updates._background_update_progress_txn(
            txn, "my_background_update", {"last_processed": last_processed}
        )
        return last_processed - prev_last_processed

    num_processed = await self.db_pool.runInteraction("_do_something", _do_something)
    await self.db_pool.updates._end_background_update("my_background_update")

    return num_processed
```

Synapse 将尝试通过给定的批处理大小和返回的处理条目数量（以及函数运行所需的时间）来限制后台更新的运行频率。  
参见 [后台更新控制器回调](../modules/background_update_controller_callbacks.md)。 

#### 布尔列

布尔列需要特殊处理，因为 SQLite 将布尔值视为整数。  
任何新的布尔列都必须添加到 `synapse/_scripts/synapse_port_db.py` 中的 `BOOLEAN_COLUMNS` 列表中。这会告诉端口脚本在将值写入 postgres 数据库之前，将 SQLite 中的整数值转换为布尔值。  

#### `event_id` 全局唯一性

`event_id` 可以被认为是全局唯一的，尽管在像 [MSC2779](https://github.com/matrix-org/matrix-spec-proposals/issues/2779) 和 [MSC2848](https://github.com/matrix-org/matrix-spec-proposals/pull/2848) 这样的地方对此话题有许多争论，至今（截至 2022-09-01）尚未有解决方案。  
在 Synapse 和甚至在 Matrix APIs 中有几个地方，如 [`GET /_matrix/federation/v1/event/{eventId}`](https://spec.matrix.org/v1.1/server-server-api/#get_matrixfederationv1eventeventid)，我们假设事件 ID 是全局唯一的。  
在数据库模式中范围化 `event_id` 时，通常最好与 `room_id` 一起使用（`PRIMARY KEY (room_id, event_id)` 和 `FOREIGN KEY(room_id) REFERENCES rooms(room_id)`），这使得灵活查找变得容易。  
例如，它可以很容易地找到并清理房间中需要清除的所有内容（无需使用子`select`查询或从`events`表中进行连接）。  
关于冲突的说明：在房间版本`1`和`2`中，可能会出现两个具有相同`event_id`的事件（在同一个或不同的房间中）。  
在房间版本`3`之后，这只能在哈希冲突的情况下发生，我们基本上希望这永远不会发生（SHA256 有巨大的密钥空间）。

#### 逐步迁移的示例

有些迁移需要逐步进行。  
一个典型的例子是任何需要进行大表扫描的操作——包括向非空表添加列、索引或 `NOT NULL` 约束——这样的迁移应尽可能作为后台更新来执行，至少在 Postgres 上是这样。  
我们可以对 SQLite 数据库更加宽松，因为它们通常用于较小的部署，并且 SQLite 不支持与 Postgres 相同的并发 DDL 操作。  
我们通常还坚持至少有一个 Synapse 版本的向后兼容性，以便管理员在升级不顺利时可以回滚 Synapse。这有时会导致需要跨多个 Synapse 版本来规划迁移。  
本节包括一个示例，未来可能会包含更多。  

##### 将一列转换为另一列，带有 `NOT NULL` 约束

此示例展示了如何引入一个新列，根据旧列的数据写入新数据，然后删除旧列。  
我们旨在实现语义等价： 

```sql
ALTER TABLE mytable ADD COLUMN new_column INTEGER;
UPDATE mytable SET new_column = old_column * 100;
ALTER TABLE mytable ALTER COLUMN new_column ADD CONSTRAINT NOT NULL;
ALTER TABLE mytable DROP COLUMN old_column;
```

###### Synapse 版本 `N`

```python
SCHEMA_VERSION = S
SCHEMA_COMPAT_VERSION = ... # unimportant at this stage
```

**不变量:**
1. `old_column` 由 Synapse 读取并由 Synapse 写入。

###### Synapse 版本 `N + 1`

```python
SCHEMA_VERSION = S + 1
SCHEMA_COMPAT_VERSION = ... # 此阶段不重要 
```

**更改:**
1. 

```sql

 ALTER TABLE mytable ADD COLUMN new_column INTEGER; 
```

**不变量:**
1. `old_column` 由 Synapse 读取并由 Synapse 写入。
2. `new_column` 由 Synapse 写入。 **注意:**
1. `new_column` 目前不能有 `NOT NULL NOT VALID` 约束，因为之前的 Synapse 版本没有写入新列（因为我们还没有更新 `SCHEMA_COMPAT_VERSION`，我们仍然需要与之前的版本兼容）。  

###### Synapse 版本 `N + 2`

```python
SCHEMA_VERSION = S + 2
SCHEMA_COMPAT_VERSION = S + 1 # 这表示我们不能回滚到 new_column 存在之前的时间 
```

**更改:**
1. 在 Postgres 上，添加一个 `NOT VALID` 约束以确保新行符合要求。  
*SQLite 没有这样的构造，但无论如何这都是不必要的，因为在 SQLite 上无法同时执行此迁移。* 
```sql

 ALTER TABLE mytable ADD CONSTRAINT CHECK new_column_not_null (new_column IS NOT NULL) NOT VALID; 
```

2. 启动后台更新以执行迁移：它应该逐渐运行，例如 
```sql

 UPDATE mytable SET new_column = old_column * 100 WHERE 0 < mytable_id AND mytable_id <= 5; 
```

这个后台更新在 SQLite 上技术上是无意义的，但您必须安排它，以便 `portdb` 脚本迁移到 Postgres 仍然有效。  
3. 在后台更新完成后，您应该在 Postgres 上运行 `VALIDATE CONSTRAINT` 以将 `NOT VALID` 约束转换为有效的约束。  
```sql

 ALTER TABLE mytable VALIDATE CONSTRAINT new_column_not_null; 
```

这将花费一些时间，但**不会**对表持有排他锁。

**不变量:**
1. `old_column` 由 Synapse 读取并由 Synapse 写入。
2. `new_column` 由 Synapse 写入，并且新行在这个字段中总是有非 `NULL` 值。

**注意:**
1. 如果您愿意，可以在 Postgres 中通过添加`NOT NULL`约束并随后删除`CHECK`约束，将`CHECK (new_column IS NOT NULL)`免费转换为`NOT NULL`约束，因为 Postgres 可以静态验证`NOT NULL`约束是由`CHECK`约束隐含的，而无需执行表扫描。  
2. 可能会有诱惑将版本`N + 2`设为冗余，通过将后台更新移至`N + 1`并将添加`NOT NULL`约束推迟到`N + 3`，但这意味着约束将始终在`N + 3`的前台验证。  
而如果保留`N + 2`步骤，那么在`N + 3`的迁移将在理想情况下很快。

###### Synapse 版本`N + 3`

```python
SCHEMA_VERSION = S + 3
SCHEMA_COMPAT_VERSION = S + 1 # 我们不能回滚到 new_column 存在之前的时间 
```

**变更:**
1. (Postgres) 在后台更新未完成的情况下，更新表以填充 `new_column` 的值。此外，使用 `VALIDATE CONSTRAINT` 使检查完全有效。  

```sql

 -- 理想情况下，你希望在 `new_column` 上建立索引，或者例如 `(new_column) WHERE new_column IS NULL`，或者如果你已经验证了 `NOT NULL` 约束，可以找到一种方法来跳过这个步骤。  
UPDATE mytable SET new_column = old_column * 100 WHERE new_column IS NULL; 
-- 如果作为后台更新的一部分已经运行过，这将是一个无操作 ALTER TABLE mytable VALIDATE CONSTRAINT new_column_not_null; 
```

2. (SQLite) 通过精确遵循[SQLite 表结构更改的 12 步程序](https://www.sqlite.org/lang_altertable.html#otheralter)来重建表。在此表重写过程中，您应该将`new_column`重新创建为`NOT NULL`，并同时填充任何未决的`NULL`值。  
遗憾的是，您还不能删除`old_column`，因为它必须存在以与 Postgres 模式兼容，如`portdb`所需。 （否则您可以一次性使用 SQLite 完成所有这些！） 
**不变量：**
1. `old_column` 由 Synapse 写入（但不再由 Synapse 读取！）。
2. `new_column` 由 Synapse 读取并由 Synapse 写入。此外，所有行在该字段中都有一个非`NULL`值，这是由模式约束保证的。 

**注意：**
1. 我们还不能删除 `old_column`，甚至不能停止写入它，因为这会破坏回滚到 Synapse 的前一个版本。
2. 应用程序代码现在可以依赖 `new_column` 已被填充。剩下的步骤只是出于清理旧列的愿望。  

###### Synapse 版本 `N + 4`

```python

SCHEMA_VERSION = S + 4
SCHEMA_COMPAT_VERSION = S + 3 # 我们不能回滚到 new_column 完全非 NULL 的时间之前 
```

**不变量:**
1. `old_column` 存在但 Synapse 不会写入或读取它。
2. `new_column` 由 Synapse 读取并写入。此外，所有行在这个字段中都有一个非 `NULL` 值，这是由模式约束保证的。**注意:**
1. 我们还不能删除 `old_column`，因为这会破坏回滚到 Synapse 的前一个版本。  
**TODO:** 可能可以放宽这个限制，直接删除该列，只要之前版本的 Synapse 检测到发生了回滚并停止尝试写入该列。  
这可以通过检查数据库的架构兼容性版本是否为 `S + 3` 来实现。  

###### Synapse 版本 `N + 5`

```python

SCHEMA_VERSION = S + 5
SCHEMA_COMPAT_VERSION = S + 4 # 我们不能回滚到 old_column 不再被触及之前的时间 
```

**更改:**
1. 

```sql

 ALTER TABLE mytable DROP COLUMN old_column; 
```